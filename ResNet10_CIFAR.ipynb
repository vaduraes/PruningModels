{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# #Code folder path\n",
    "# %cd /content/drive/My Drive/ECE591_DL_CL_PROJECT/\n",
    "\n",
    "#device config\n",
    "torch.cuda.set_device(1)#Select GPU device 1\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#Datasets\n",
    "#Tiny-imagenet: http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "#Tiny-imagenet-C: https://zenodo.org/records/2469796\n",
    "\n",
    "#CIFAR-10:  https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "#CIFAR-10C: https://zenodo.org/records/2535967\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of transformations when called\n",
    "\n",
    "class GetTransforms():\n",
    "    '''Returns a list of transformations when type as requested amongst train/test\n",
    "       Transforms('train') = list of transforms to apply on training data\n",
    "       Transforms('test') = list of transforms to apply on testing data'''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def trainparams(self):\n",
    "        train_transformations = [ #resises the image so it can be perfect for our model.\n",
    "            # transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
    "            # transforms.RandomRotation((-7,7)),     #Rotates the image to a specified angel\n",
    "            # transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "            # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "            transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)) #Normalize all the images\n",
    "            ]\n",
    "\n",
    "        return train_transformations\n",
    "\n",
    "    def testparams(self):\n",
    "        test_transforms = [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)) #Normalize all the images\n",
    "        ]\n",
    "        return test_transforms\n",
    "\n",
    "transformations = GetTransforms()\n",
    "train_transforms = transforms.Compose(transformations.trainparams())#transforms.Compose(\n",
    "test_transforms = transforms.Compose(transformations.testparams()) #transforms.Compose("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Download CIFAR-10 Dataset\n",
    "class GetCIFAR10_TrainData():\n",
    "    def __init__(self, dir_name:str):\n",
    "        self.dirname = dir_name\n",
    "\n",
    "    def download_train_data(self):\n",
    "        return datasets.CIFAR10(self.dirname, train=True, download=True, transform=train_transforms)\n",
    "\n",
    "    def download_test_data(self):\n",
    "        return datasets.CIFAR10(self.dirname, train=False, download=True, transform=test_transforms)\n",
    "\n",
    "data = GetCIFAR10_TrainData('./Datasets/CIFAR-10')\n",
    "trainset = data.download_train_data()\n",
    "testset = data.download_test_data()\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512,shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "           Dropout-5           [-1, 64, 32, 32]               0\n",
      "            Conv2d-6           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "           Dropout-8           [-1, 64, 32, 32]               0\n",
      "        BasicBlock-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "          Dropout-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "          Dropout-15           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-16           [-1, 64, 32, 32]               0\n",
      "           Conv2d-17          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "          Dropout-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "          Dropout-22          [-1, 128, 16, 16]               0\n",
      "           Conv2d-23          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-24          [-1, 128, 16, 16]             256\n",
      "          Dropout-25          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-26          [-1, 128, 16, 16]               0\n",
      "           Conv2d-27          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-28          [-1, 128, 16, 16]             256\n",
      "          Dropout-29          [-1, 128, 16, 16]               0\n",
      "           Conv2d-30          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
      "          Dropout-32          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-33          [-1, 128, 16, 16]               0\n",
      "           Conv2d-34            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "          Dropout-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-38            [-1, 256, 8, 8]             512\n",
      "          Dropout-39            [-1, 256, 8, 8]               0\n",
      "           Conv2d-40            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 8, 8]             512\n",
      "          Dropout-42            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-43            [-1, 256, 8, 8]               0\n",
      "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
      "          Dropout-46            [-1, 256, 8, 8]               0\n",
      "           Conv2d-47            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
      "          Dropout-49            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-50            [-1, 256, 8, 8]               0\n",
      "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
      "          Dropout-53            [-1, 512, 4, 4]               0\n",
      "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
      "          Dropout-56            [-1, 512, 4, 4]               0\n",
      "           Conv2d-57            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-58            [-1, 512, 4, 4]           1,024\n",
      "          Dropout-59            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-60            [-1, 512, 4, 4]               0\n",
      "           Conv2d-61            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-62            [-1, 512, 4, 4]           1,024\n",
      "          Dropout-63            [-1, 512, 4, 4]               0\n",
      "           Conv2d-64            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-65            [-1, 512, 4, 4]           1,024\n",
      "          Dropout-66            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-67            [-1, 512, 4, 4]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 15.44\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 58.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#following: https://www.kaggle.com/code/greatcodes/pytorch-cnn-resnet18-cifar10/notebook\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        DROPOUT = 0.1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes),\n",
    "                nn.Dropout(DROPOUT)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.dropout(self.bn1(self.conv1(x))))\n",
    "        out = self.dropout(self.bn2(self.conv2(out)))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1) #the blocks we repeat have stride 1\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "model = ResNet18().to(device)\n",
    "summary(model, input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, device, train_dataloader, optimizer, train_acc, train_losses):\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)\n",
    "        loss = F.nll_loss(y_pred, target) #negative log likelihood loss\n",
    "\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step() #Performs a single optimization step (parameter update).\n",
    "\n",
    "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        processed += len(data)\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_description(desc=f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "        train_acc.append(100*correct/processed)\n",
    "\n",
    "def model_testing(model, device, test_dataloader, test_acc, test_losses, misclassified = []):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    # label = 0\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for index, (data, target) in enumerate(test_dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            for d,i,j in zip(data, pred, target):\n",
    "                if i != j:\n",
    "                    misclassified.append([d.cpu(),i[0].cpu(),j.cpu()])\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))\n",
    "\n",
    "    test_acc.append(100. * correct / len(test_dataloader.dataset))\n",
    "    return misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.204745888710022 Batch_id=97 Accuracy=38.75: 100%|██████████| 98/98 [00:10<00:00,  9.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4174, Accuracy: 4974/10000 (49.74%)\n",
      "\n",
      "EPOCHS : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.004228949546814 Batch_id=97 Accuracy=57.81: 100%|██████████| 98/98 [00:10<00:00,  9.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1379, Accuracy: 5948/10000 (59.48%)\n",
      "\n",
      "EPOCHS : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9116363525390625 Batch_id=97 Accuracy=67.15: 100%|██████████| 98/98 [00:10<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0822, Accuracy: 6263/10000 (62.63%)\n",
      "\n",
      "EPOCHS : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.807068407535553 Batch_id=97 Accuracy=72.99: 100%|██████████| 98/98 [00:10<00:00,  9.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8499, Accuracy: 7069/10000 (70.69%)\n",
      "\n",
      "EPOCHS : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6352121829986572 Batch_id=97 Accuracy=77.26: 100%|██████████| 98/98 [00:10<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7794, Accuracy: 7424/10000 (74.24%)\n",
      "\n",
      "EPOCHS : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4930751919746399 Batch_id=97 Accuracy=80.60: 100%|██████████| 98/98 [00:10<00:00,  9.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7203, Accuracy: 7655/10000 (76.55%)\n",
      "\n",
      "EPOCHS : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.49519839882850647 Batch_id=97 Accuracy=83.44: 100%|██████████| 98/98 [00:10<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6601, Accuracy: 7772/10000 (77.72%)\n",
      "\n",
      "EPOCHS : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.05, patience=2, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n",
    "\n",
    "\n",
    "train_acc = []\n",
    "train_losses = []\n",
    "test_acc = []\n",
    "test_losses = []\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(f'EPOCHS : {i}')\n",
    "    model_training(model, device, trainloader, optimizer, train_acc, train_losses)\n",
    "    scheduler.step(train_losses[-1])\n",
    "    misclassified = model_testing(model, device, testloader, test_acc, test_losses)\n",
    "\n",
    "torch.save(model.state_dict(), \"./Networks/ResNet18_CIFAR10_V0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(8,8))\n",
    "\n",
    "axs[0,0].set_title('Train Losses')\n",
    "axs[0,1].set_title('Training Accuracy')\n",
    "axs[1,0].set_title('Test Losses')\n",
    "axs[1,1].set_title('Test Accuracy')\n",
    "\n",
    "axs[0,0].plot(train_losses)\n",
    "axs[0,1].plot(train_acc)\n",
    "axs[1,0].plot(test_losses)\n",
    "axs[1,1].plot(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
