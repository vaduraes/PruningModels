{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# #Code folder path\n",
    "# %cd /content/drive/My Drive/ECE591_DL_CL_PROJECT/\n",
    "\n",
    "#device config\n",
    "torch.cuda.set_device(1)#Select GPU device 1\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Get Packages\n",
    "sys.path.append('./Tools')\n",
    "\n",
    "#Network architectures\n",
    "from ResNet18_CIFAR10 import ResNet18_CIFAR10_Model\n",
    "from ResNet18_TINYIMAGENET import ResNet18_TINYIMAGENET_Model\n",
    "from VGG16_CIFAR10 import VGG16_CIFAR10_Model\n",
    "from VGG16_TINYIMAGENET import VGG16_TINYIMAGENET_Model\n",
    "\n",
    "#Non Corrupted DataLoaders\n",
    "from CIFAR10_LOADER import CIFAR10DataLoader\n",
    "from TINYIMAGENET_LOADER import TINYIMAGENETDataLoader\n",
    "\n",
    "#Error Metrics\n",
    "from ErrorMetrics import Evaluate_Model_TOP1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Network weights\n",
    "ResNet18_CIFAR10_Weights= torch.load(\"./Networks/ResNet18_CIFAR10_V0.pt\")\n",
    "ResNet18_TINYIMAGENET_Weights=torch.load(\"./Networks/ResNet18_TINY_IMAGENET_V0.pt\")\n",
    "VGG16_CIFAR10_Weights=torch.load(\"./Networks/VGG16_CIFAR10_V0.pt\")\n",
    "VGG16_TINYIMAGENET_Weights=torch.load(\"./Networks/VGG16_TINY_IMAGENET_V0.pt\")\n",
    "\n",
    "#Unpruned Models\n",
    "ResNet18_CIFAR10_0P=ResNet18_CIFAR10_Model()\n",
    "ResNet18_CIFAR10_0P.load_state_dict(ResNet18_CIFAR10_Weights)\n",
    "\n",
    "ResNet18_TINYIMAGENET_0P=ResNet18_TINYIMAGENET_Model()\n",
    "ResNet18_TINYIMAGENET_0P.load_state_dict(ResNet18_TINYIMAGENET_Weights)\n",
    "\n",
    "VGG16_CIFAR10_0P=VGG16_CIFAR10_Model()\n",
    "VGG16_CIFAR10_0P.load_state_dict(VGG16_CIFAR10_Weights)\n",
    "\n",
    "VGG16_TINYIMAGENET_0P=VGG16_TINYIMAGENET_Model()\n",
    "VGG16_TINYIMAGENET_0P.load_state_dict(VGG16_TINYIMAGENET_Weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader_CIFAR10, testloader_CIFAR10=CIFAR10DataLoader() #Load Data for CIFAR10\n",
    "trainloader_TINYIMAGENET, testloader_TINYIMAGENET=TINYIMAGENETDataLoader() #Load Data for TINYIMAGENET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Non Corrupted Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_CIFAR10_0P: Loss: 0.3436, Accuracy: 89.04%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_TINYIMAGENET_0P: Loss: 1.7581, Accuracy: 60.36%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_CIFAR10_0P: Loss: 0.3662, Accuracy: 89.09%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_TINYIMAGENET_0P: Loss: 2.7202, Accuracy: 54.76%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Test Accuracy\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(ResNet18_CIFAR10_0P, device, testloader_CIFAR10) #ResNet18 on CIFAR10\n",
    "print(f\"ResNet18_CIFAR10_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n",
    "\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(ResNet18_TINYIMAGENET_0P, device, testloader_TINYIMAGENET) #ResNet18 on TINYIMAGENET\n",
    "print(f\"ResNet18_TINYIMAGENET_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n",
    "\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(VGG16_CIFAR10_0P, device, testloader_CIFAR10) #VGG16 on CIFAR10\n",
    "print(f\"VGG16_CIFAR10_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n",
    "\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(VGG16_TINYIMAGENET_0P, device, testloader_TINYIMAGENET) #VGG16 on TINYIMAGENET\n",
    "print(f\"VGG16_TINYIMAGENET_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:19<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_CIFAR10_0P: Loss: 0.1349, Accuracy: 95.64%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:00<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_TINYIMAGENET_0P: Loss: 0.5043, Accuracy: 87.22%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:19<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_CIFAR10_0P: Loss: 0.1292, Accuracy: 95.64%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:01<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_TINYIMAGENET_0P: Loss: 0.0141, Accuracy: 99.78%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Accuracy\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(ResNet18_CIFAR10_0P, device, trainloader_CIFAR10) #ResNet18 on CIFAR10\n",
    "print(f\"ResNet18_CIFAR10_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n",
    "\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(ResNet18_TINYIMAGENET_0P, device, trainloader_TINYIMAGENET) #ResNet18 on TINYIMAGENET\n",
    "print(f\"ResNet18_TINYIMAGENET_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n",
    "\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(VGG16_CIFAR10_0P, device, trainloader_CIFAR10) #VGG16 on CIFAR10\n",
    "print(f\"VGG16_CIFAR10_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")\n",
    "\n",
    "loss, acc, misclassified=Evaluate_Model_TOP1(VGG16_TINYIMAGENET_0P, device, trainloader_TINYIMAGENET) #VGG16 on TINYIMAGENET\n",
    "print(f\"VGG16_TINYIMAGENET_0P: Loss: {loss:.4f}, Accuracy: {acc:.2f}%\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
