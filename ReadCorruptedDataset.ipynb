{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# #Code folder path\n",
    "# %cd /content/drive/My Drive/ECE591_DL_CL_PROJECT/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrupted CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10C_corruptions = [\"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \n",
    "               \"fog\", \"frost\", \"gaussian_blur\", \"gaussian_noise\",\"glass_blur\",\n",
    "               \"impulse_noise\", \"jpeg_compression\", \"motion_blur\",\n",
    "               \"pixelate\", \"saturate\", \"shot_noise\", \"snow\", \"spatter\", \"speckle_noise\",\"zoom_blur\"]\n",
    "\n",
    "#https://github.com/tanimutomo/cifar10-c-eval/blob/master\n",
    "class CIFAR10C(datasets.VisionDataset):\n",
    "    def __init__(self, root :str, name :str,transform):\n",
    "\n",
    "        corruptions = [\"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \n",
    "               \"fog\", \"frost\", \"gaussian_blur\", \"gaussian_noise\",\"glass_blur\",\n",
    "               \"impulse_noise\", \"jpeg_compression\", \"motion_blur\",\n",
    "               \"pixelate\", \"saturate\", \"shot_noise\", \"snow\", \"spatter\", \"speckle_noise\",\"zoom_blur\"]\n",
    "        \n",
    "        assert name in corruptions\n",
    "        super(CIFAR10C, self).__init__(root, transform=transform)\n",
    "        data_path = os.path.join(root, name + '.npy')\n",
    "        target_path = os.path.join(root, 'labels.npy')\n",
    "        \n",
    "        self.data = np.load(data_path)\n",
    "        self.targets = np.load(target_path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img, targets = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def CIFAR10C_DataLoader(root, batch_size=64):\n",
    "    transformList = [transforms.ToTensor(),transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261))]\n",
    "    transform = transforms.Compose(transformList)\n",
    "    Dataloaders={}\n",
    "\n",
    "    CIFAR10C_corruptions = [\"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \n",
    "               \"fog\", \"frost\", \"gaussian_blur\", \"gaussian_noise\",\"glass_blur\",\n",
    "               \"impulse_noise\", \"jpeg_compression\", \"motion_blur\",\n",
    "               \"pixelate\", \"saturate\", \"shot_noise\", \"snow\", \"spatter\", \"speckle_noise\",\"zoom_blur\"]\n",
    "    \n",
    "    for cname in CIFAR10C_corruptions:\n",
    "        dataset = CIFAR10C(root,cname,transform=transform)\n",
    "        CIFARC_Loader=torch.utils.data.DataLoader(dataset, batch_size=256,shuffle=False, num_workers=2)\n",
    "        Dataloaders[cname]=CIFARC_Loader\n",
    "\n",
    "    return Dataloaders\n",
    "\n",
    "root=\"./Datasets/CIFAR-10/CIFAR-10-C/\"\n",
    "Dataloaders=CIFAR10C_DataLoader(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (data, target) in enumerate(Dataloaders[\"motion_blur\"]):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRUPTED TINY IMAGENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TinyImagenetC_DataLoader(root=\"./Datasets/TINY-IMAGENET/TinyImageNet-C/Tiny-ImageNet-C\",batch_size=64):\n",
    "\n",
    "    TinyImagenetC_corruptions = [\"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \n",
    "               \"fog\", \"frost\", \"gaussian_blur\", \"gaussian_noise\",\"glass_blur\",\n",
    "               \"impulse_noise\", \"jpeg_compression\", \"motion_blur\",\n",
    "               \"pixelate\", \"saturate\", \"shot_noise\", \"snow\", \"spatter\", \"speckle_noise\",\"zoom_blur\"]\n",
    "\n",
    "    SeverityLevels=[\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "\n",
    "    transformList = [transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    "    transform = transforms.Compose(transformList)\n",
    "\n",
    "    Dataloaders={}\n",
    "    for cname in TinyImagenetC_corruptions:\n",
    "        Level_Dataloaders={}\n",
    "        for clevel in SeverityLevels:\n",
    "            data_path=os.path.join(root, cname,clevel)\n",
    "            Dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "            Dataloader = torch.utils.data.DataLoader(Dataset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "            Level_Dataloaders[clevel]=Dataloader #Levels for individual corruptions\n",
    "\n",
    "        Dataloaders[cname]=Level_Dataloaders #All Corruptions and their levels\n",
    "\n",
    "    return Dataloaders\n",
    "\n",
    "Dataloaders=TinyImagenetC_DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (data, target) in enumerate(Dataloaders[\"frost\"][\"2\"]):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([149, 293, 133, 637, 950, 242, 263, 101,  73,  98, 874, 167, 770, 144,\n",
       "        608, 875, 823, 246, 891, 146, 813, 545, 554, 653, 401, 182, 312, 478,\n",
       "        319, 926, 423, 420, 637, 665, 204, 184,  88, 950, 549, 452, 736, 614,\n",
       "        568, 658, 323, 654,  76, 820, 713, 870, 480, 555, 994, 271, 315, 684,\n",
       "        938, 412, 194, 434, 215, 821, 587, 580])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
