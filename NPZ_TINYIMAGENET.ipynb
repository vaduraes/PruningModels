{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For good drive it is faster to convert individual images to numpy arrays and then load them\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.58s/it]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.45s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.50s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.54s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.51s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.55s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.48s/it]]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.64s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.52s/it]]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.68s/it]]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.51s/it]t]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.55s/it]t]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.58s/it]t]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.55s/it]t]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.62s/it]t]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.53s/it]t]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.58s/it]t]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.66s/it]t]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.53s/it]t]\n",
      "100%|██████████| 19/19 [02:27<00:00,  7.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# TinyImagenetC\n",
    "output_path=\"./Datasets/TINY-IMAGENET/TinyImageNet-C_NPZ/\"\n",
    "root=\"./Datasets/TINY-IMAGENET/TinyImageNet-C/Tiny-ImageNet-C\"\n",
    "\n",
    "\n",
    "    \n",
    "TinyImagenetC_corruptions = [\"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \n",
    "            \"fog\", \"frost\", \"gaussian_blur\", \"gaussian_noise\",\"glass_blur\",\n",
    "            \"impulse_noise\", \"jpeg_compression\", \"motion_blur\",\n",
    "            \"pixelate\", \"saturate\", \"shot_noise\", \"snow\", \"spatter\", \"speckle_noise\",\"zoom_blur\"]\n",
    "\n",
    "SeverityLevels=[\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "\n",
    "\n",
    "for cname in tqdm(TinyImagenetC_corruptions):\n",
    "    for clevel in tqdm(SeverityLevels):\n",
    "        data = {\"images\": [], \"labels\": []}\n",
    "\n",
    "        data_path = os.path.join(root, cname, clevel)\n",
    "        Dataset = datasets.ImageFolder(data_path, transform=None)\n",
    "        \n",
    "        for img, label in Dataset:\n",
    "            img = img.convert('RGB')  # Ensure the image is in RGB mode\n",
    "            img_bytes = np.array(img, dtype=np.uint8)\n",
    "\n",
    "            data[\"images\"].append(img_bytes)\n",
    "            data[\"labels\"].append(label)\n",
    "\n",
    "        np.savez(output_path + cname + \"_\" + clevel + \".npz\", **data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:13<00:00, 7648.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#Create Loaders\n",
    "DataPath=\"./Datasets/TINY-IMAGENET/tiny-imagenet-200/\"\n",
    "output_path=\"./Datasets/TINY-IMAGENET/tiny-imagenet-200_NPZ/\"\n",
    "trainset = datasets.ImageFolder(DataPath+'/train', transform=None)\n",
    "\n",
    "\n",
    "data = {\"images\": [], \"labels\": []}\n",
    "for img, label in tqdm(trainset):\n",
    "    \n",
    "    img_bytes = np.array(img, dtype=np.uint8)\n",
    "\n",
    "    data[\"images\"].append(img_bytes)\n",
    "    data[\"labels\"].append(label)\n",
    "\n",
    "np.savez(output_path + \"train.npz\", **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 7543.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Create Loaders\n",
    "DataPath=\"./Datasets/TINY-IMAGENET/tiny-imagenet-200/\"\n",
    "output_path=\"./Datasets/TINY-IMAGENET/tiny-imagenet-200_NPZ/\"\n",
    "testset = datasets.ImageFolder(DataPath+'/test_pro', transform=None)\n",
    "\n",
    "data = {\"images\": [], \"labels\": []}\n",
    "for img, label in tqdm(testset):\n",
    "    \n",
    "    img_bytes = np.array(img, dtype=np.uint8)\n",
    "\n",
    "    data[\"images\"].append(img_bytes)\n",
    "    data[\"labels\"].append(label)\n",
    "\n",
    "np.savez(output_path + \"test_pro.npz\", **data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
